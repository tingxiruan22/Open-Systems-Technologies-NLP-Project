{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ad3b628",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e05bb4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py10/lib/python3.10/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# Load the sentence transformer model\n",
    "#from resume_parser import resumeparse\n",
    "#from transformers import BertModel, BertTokenizer\n",
    "#import torch\n",
    "import glob\n",
    "import os\n",
    "import pinecone\n",
    "import numpy as np\n",
    "import json\n",
    "#from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Index\n",
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "from ttkthemes import ThemedTk\n",
    "from tkinter.font import Font\n",
    "import sys\n",
    "from PyPDF2 import PdfFileReader\n",
    "from docx import Document\n",
    "from bs4 import BeautifulSoup\n",
    "from PyPDF2 import PdfReader\n",
    "import textract\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import re\n",
    "from tkinter import scrolledtext, messagebox\n",
    "import urllib\n",
    "import urllib.parse\n",
    "from pymongo.mongo_client import MongoClient\n",
    "import unidecode\n",
    "from tkinter import BooleanVar\n",
    "import time\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9777a5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5bfb1b",
   "metadata": {},
   "source": [
    "## Pinecone and MongoDB initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7319db08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pinecone vector database\n",
    "pinecone.init(api_key=\"bc6d7eb3-c8aa-4537-acaa-f27f9c417c9f\", environment= 'us-west4-gcp')\n",
    "filename1 = 'resumes.json'\n",
    "pinecone.init(api_key=\"bc6d7eb3-c8aa-4537-acaa-f27f9c417c9f\", environment= 'us-west4-gcp')\n",
    "index_name = \"cloudresumes\"\n",
    "index = pinecone.Index(index_name=index_name)\n",
    "\n",
    "\n",
    "# openai embedding\n",
    "model_name = 'gpt-4'\n",
    "# Set up your own OpenAI private key\n",
    "\n",
    "embed = OpenAIEmbeddings(\n",
    "    model=model_name,\n",
    "    openai_api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "\n",
    "# MongoDB\n",
    "# Set up with your own account\n",
    "client = MongoClient(uri)\n",
    "db = client[\"resumesamples\"]\n",
    "collection = db[\"re\"]           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106ae8e7",
   "metadata": {},
   "source": [
    "## Process Resuems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f7ef1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(file_path, file_name):\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        pdf = PdfReader(file)\n",
    "        text = ' '.join([pdf.pages[i].extract_text() for i in range(len(pdf.pages))])\n",
    "\n",
    "    return extract_info(text, file_name)\n",
    "\n",
    "def process_docx(file_path, file_name):\n",
    "    doc = Document(file_path)\n",
    "    text = \" \".join([paragraph.text for paragraph in doc.paragraphs])\n",
    "\n",
    "    return extract_info(text, file_name)\n",
    "\n",
    "def process_html(file_path, file_name):\n",
    "    with open(file_path, \"r\", encoding='iso-8859-1') as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "\n",
    "    return extract_info(text, file_name)\n",
    "\n",
    "def process_doc(file_path, file_name):\n",
    "    text = textract.process(file_path).decode('utf8')\n",
    "\n",
    "    return extract_info(text, file_name)\n",
    "\n",
    "def process_txt(file_path, file_name):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "\n",
    "    return extract_info(text, file_name)\n",
    "\n",
    "def extract_info(text, file_name):\n",
    "    return {'id': file_name, 'text': text}\n",
    "\n",
    "def read_resume_files(resume_folder):\n",
    "    \"\"\"\n",
    "    read all files from a folder and return a dictionary of json format\n",
    "    \"\"\"\n",
    "    resume_files = os.listdir(resume_folder)\n",
    "    print(f\"there are {len(resume_files)} resumes\")\n",
    "\n",
    "    json_resumes = []\n",
    "    # Iterate over all files\n",
    "    for file in resume_files:\n",
    "        try:\n",
    "            file_path = os.path.join(resume_folder, file)\n",
    "            \n",
    "            if file.endswith('.pdf'):\n",
    "                json_resumes.append(process_pdf(file_path, file))\n",
    "            elif file.endswith('.docx'):\n",
    "                json_resumes.append(process_docx(file_path, file))\n",
    "            elif file.endswith('.html'):\n",
    "                json_resumes.append(process_html(file_path, file))\n",
    "            elif file.endswith('.doc'):\n",
    "                json_resumes.append(process_doc(file_path, file))\n",
    "            elif file.endswith('.txt'):\n",
    "                json_resumes.append(process_txt(file_path, file))\n",
    "            else:\n",
    "                print(f\"Unsupported file type: {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {file} due to {e}\" )\n",
    "\n",
    "    return json_resumes\n",
    "\n",
    "def read_single_resume_file(filepath):\n",
    "    \"\"\"\n",
    "    read a single resume file and return a dictionary of ids and text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_name = os.path.basename(filepath)\n",
    "\n",
    "        if filepath.endswith('.pdf'):\n",
    "            return process_pdf(filepath, file_name)\n",
    "        elif filepath.endswith('.docx'):\n",
    "            return process_docx(filepath, file_name)\n",
    "        elif filepath.endswith('.html'):\n",
    "            return process_html(filepath, file_name)\n",
    "        elif filepath.endswith('.doc'):\n",
    "            return process_doc(filepath, file_name)\n",
    "        elif filepath.endswith('.txt'):\n",
    "            return process_txt(filepath, file_name)\n",
    "        else:\n",
    "            print(f\"Unsupported file type: {file_name}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {file_name} due to {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca51631",
   "metadata": {},
   "source": [
    "# Use OpenAi's embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef30b8cb",
   "metadata": {},
   "source": [
    "### Skip the following lines, create new Pinecone index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbb4c4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Do not run this line, already exsists\n",
    "# # Create a new Pinecone index\n",
    "# pinecone.create_index(name=index_name, metric=\"cosine\", shards=1, dimension = 1536)\n",
    "# # Connect to the index\n",
    "# index = pinecone.Index(index_name=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe76bae",
   "metadata": {},
   "source": [
    "### start next lines, init GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e4ed6f",
   "metadata": {},
   "source": [
    "## DB functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8733481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_matches(index, embed, job_description, top_k):\n",
    "    \"\"\"get top matches using Pinecone's vector search, the model is specified by embed\"\"\"\n",
    "    # Convert job description into embeddings\n",
    "    query_vector = embed.embed_documents([job_description])\n",
    "    query_vector = query_vector[0] # Select the first (and only) embedding\n",
    "    #print(query_vector)\n",
    "\n",
    "    # Query Pinecone for similar vectors\n",
    "    query_result = index.query(queries=[query_vector], top_k=top_k, namespace=index_name)\n",
    "    #print(len(query_vector))\n",
    "\n",
    "    # Get IDs of top_k similar vectors\n",
    "    print(query_result)\n",
    "\n",
    "    return query_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d262aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_all_resumes_from_db():\n",
    "    \"\"\"\n",
    "    fetch all resumes from MongoDB\n",
    "    return: a list of dictionaries\n",
    "    \"\"\"\n",
    "    cursor = collection.find({}, {'_id': 0})  # Exclude the '_id' field.\n",
    "\n",
    "    json_resumes = [doc for doc in cursor]\n",
    "\n",
    "    return json_resumes\n",
    "\n",
    "def fetch_resume_by_id(resume_id):\n",
    "    \"\"\"Fetch a single resume by ID from MongoDB instead of the local JSON file\"\"\"\n",
    "    # Fetch the resume from MongoDB\n",
    "    resume = collection.find_one({\"id\": resume_id}, {'_id': 0})\n",
    "    return str(resume) if resume else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82d4bb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_id(id_string):\n",
    "    return ''.join([i if ord(i) < 128 else '_' for i in id_string])\n",
    "\n",
    "def upload_resumes():\n",
    "\n",
    "    # Open directory dialog and get folder path\n",
    "    resume_folder = filedialog.askdirectory()\n",
    "    print(f\"Selected folder: {resume_folder}\")\n",
    "\n",
    "    # Connect to MongoDB\n",
    "    # password required\n",
    "    # uri required\n",
    "    client = MongoClient(uri)\n",
    "    db = client[\"resumesamples\"]\n",
    "    collection = db[\"re\"]\n",
    "    print(f\"MongoDB connected\")\n",
    "    \n",
    "    for dirpath, dirs, files in os.walk(resume_folder):\n",
    "        # Process the resumes\n",
    "        for filename in files:\n",
    "            fullpath = os.path.join(dirpath, filename)\n",
    "            try:\n",
    "                resume = read_single_resume_file(fullpath)\n",
    "\n",
    "                # Clean the resume ID before processing\n",
    "                ascii_id = clean_id(resume[\"id\"])\n",
    "                resume[\"id\"] = ascii_id\n",
    "\n",
    "                # Check if the resume already exists in MongoDB and Pinecone\n",
    "                existing_document = collection.find_one({\"id\": resume[\"id\"], \"pinecone_id\": {\"$exists\": True}})\n",
    "                if existing_document is not None:\n",
    "                    print(f'Skipped document with id: {resume[\"id\"]} as it already exists in MongoDB and Pinecone.')\n",
    "                    continue\n",
    "\n",
    "                # Write each resume to MongoDB\n",
    "                existing_document = collection.find_one({\"id\": resume[\"id\"]})\n",
    "                if existing_document is not None:\n",
    "                    # Update the existing document\n",
    "                    result = collection.update_one({\"id\": resume[\"id\"]}, {\"$set\": resume})\n",
    "                    print(f'Updated the document with id: {resume[\"id\"]}')\n",
    "                else:\n",
    "                    # Insert a new document\n",
    "                    result = collection.insert_one(resume)\n",
    "                    print(f'Added a new document with id: {resume[\"id\"]}')\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process file: {fullpath}, Error: {e}\")\n",
    "                continue  # this will skip the rest of this loop and go to the next file\n",
    "\n",
    "    # Feedback to user\n",
    "    print(f\"MongoDB Updated for folder: {resume_folder}\")\n",
    "    \n",
    "    #update Pinecone\n",
    "    update_pinecone()\n",
    "\n",
    "\n",
    "def insert_into_pinecone(index, embed, json_resumes):    \n",
    "    inserted_ids = []\n",
    "    for resume in json_resumes:\n",
    "        try:\n",
    "            \n",
    "            all_fields_text = \" \".join([str(field) + ':' + str(resume.get(field, \"\")) + \";\" for field in resume.keys()-'id'])\n",
    "            # Transform the text into embeddings using OpenAI\n",
    "            embeddings = embed.embed_documents([all_fields_text])\n",
    "\n",
    "            # Convert embeddings to a list as Pinecone expects a list or numpy array\n",
    "            embeddings = embeddings[0]  # Select the first element because model.encode returns a list of embeddings\n",
    "\n",
    "            # Convert the resume ID to ASCII-compatible format using the clean_id function\n",
    "            ascii_id = clean_id(resume['id'])\n",
    "\n",
    "            # upsert (update/insert) the vector into Pinecone using the cleaned ID\n",
    "            upsert_response = index.upsert(vectors=[{'id': ascii_id, 'values': embeddings}], namespace=index_name)\n",
    "\n",
    "            print(f\"Finished inserting {ascii_id} into Pinecone\")\n",
    "            inserted_ids.append(ascii_id)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {ascii_id}, Error: {e}\")\n",
    "            continue\n",
    "\n",
    "    return inserted_ids\n",
    "\n",
    "def update_pinecone():\n",
    "    # ... (existing code) ...\n",
    "    # password\n",
    "    # uri\n",
    "    client = MongoClient(uri)\n",
    "    db = client[\"resumesamples\"]\n",
    "    collection = db[\"re\"]\n",
    "    # pinecone init\n",
    "    index = pinecone.Index(index_name=index_name)\n",
    "\n",
    "    # Only select the resumes with IDs not in pinecone_ids\n",
    "    all_resumes = list(collection.find({\"pinecone_id\": {\"$exists\": False}}))\n",
    "    json_resumes = all_resumes\n",
    "\n",
    "    # Update the pinecone_ids\n",
    "    new_ids = insert_into_pinecone(index, embed, json_resumes)\n",
    "    for id in new_ids:\n",
    "        # Update MongoDB with new Pinecone IDs\n",
    "        collection.update_one({\"id\": id}, {\"$set\": {\"pinecone_id\": id}})\n",
    "\n",
    "    print(\"Updated Pinecone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf166b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush_databases():\n",
    "    # ... (existing code) ...\n",
    "\n",
    "    # Flush MongoDB\n",
    "    collection.delete_many({})\n",
    "\n",
    "    print(\"MongoDB has been flushed.\")\n",
    "\n",
    "    # Connect to Pinecone\n",
    "    # pinecone init\n",
    "    index = pinecone.Index(index_name=index_name)\n",
    "\n",
    "    # Flush Pinecone\n",
    "    index.delete(deleteAll='true', namespace=index_name)\n",
    "    \n",
    "    print(\"Pinecone has been flushed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b825b6d",
   "metadata": {},
   "source": [
    "## Layer2 Boolean Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c81765dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_query(query):\n",
    "    \"\"\" boolean search parse query to tokens\"\"\"\n",
    "    query = query.lower()\n",
    "    tokens = re.findall(r'\\([^)]*\\)|\"[^\"]*\"|\\S+', query)\n",
    "    return [token.strip('\"') for token in tokens]\n",
    "\n",
    "def boolean_search(resume_text, query):\n",
    "    \"\"\" implement boolean search return True/False\"\"\"\n",
    "    \n",
    "    if not resume_text:\n",
    "        return False\n",
    "    \n",
    "    resume_text = resume_text.lower()\n",
    "\n",
    "    tokens = parse_query(query)\n",
    "\n",
    "    def process_keyword(keyword, negation=False):\n",
    "        if '*' in keyword:  # handle wildcard searches\n",
    "            keyword = keyword.replace('*', '.*')  # convert * to regex pattern\n",
    "            keyword_present = bool(re.search(keyword, resume_text))\n",
    "        else:\n",
    "            keyword_present = keyword in resume_text\n",
    "\n",
    "        if negation:\n",
    "            print(f\"Keyword '{keyword}' is not in text: {not keyword_present}\")  # Debug print statement\n",
    "            return not keyword_present\n",
    "        else:\n",
    "            print(f\"Keyword '{keyword}' is in text: {keyword_present}\")  # Debug print statement\n",
    "            return keyword_present\n",
    "\n",
    "    def evaluate_expression(tokens):\n",
    "        if not tokens:\n",
    "            return False\n",
    "\n",
    "        keyword = tokens.pop(0)\n",
    "        print(f\"Processing keyword: {keyword}\")  # Debug print statement\n",
    "\n",
    "        negation = False\n",
    "        if keyword == \"not\":\n",
    "            negation = True\n",
    "            keyword = tokens.pop(0)\n",
    "\n",
    "        if keyword.startswith(\"(\"):\n",
    "            result = evaluate_expression(parse_query(keyword.strip(\"()\")))\n",
    "        elif keyword:\n",
    "            result = process_keyword(keyword, negation)\n",
    "        \n",
    "        while tokens:\n",
    "            operator = tokens.pop(0)\n",
    "            print(f\"Processing operator: {operator}\")  # Debug print statement\n",
    "\n",
    "            if operator == \")\":\n",
    "                return result\n",
    "\n",
    "            next_keyword = tokens.pop(0) if tokens else None\n",
    "            print(f\"Processing next keyword: {next_keyword}\")  # Debug print statement\n",
    "\n",
    "            if next_keyword and next_keyword.startswith(\"(\"):\n",
    "                next_result = evaluate_expression(parse_query(next_keyword.strip(\"()\")))\n",
    "            elif next_keyword:\n",
    "                next_result = process_keyword(next_keyword)\n",
    "\n",
    "            print(f\"Intermediate result before applying operator: {result}\")  # Debug print statement\n",
    "            if operator == 'and':\n",
    "                result = result and next_result\n",
    "            elif operator == 'or':\n",
    "                result = result or next_result\n",
    "            elif operator == 'not':\n",
    "                result = result and not next_result\n",
    "            print(f\"Intermediate result after applying operator: {result}\")  # Debug print statement\n",
    "\n",
    "        return result\n",
    "\n",
    "    return evaluate_expression(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097d4ffe",
   "metadata": {},
   "source": [
    "## Layer3 AI check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7789f5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AI_check(resume_text, job_description, strict_requirements=None):\n",
    "    # OpenAI key\n",
    "    prompt = \"\"\"\n",
    "    \"Answer Yes or No: \n",
    "    You are a knowledgeable hiring manager. Your task is to review the given resume and check if the candidate satisfies the job description or potentially qualifies the job. \n",
    "    Please respond with a one or two sentences reason 'Yes, He/She is. Because...' if the candidate satisfies the job description, and 'No, because...' otherwise. \n",
    "    Don't be strict on it, but you can infer from his resume on whether he will be able to do this job. For example, a Phd in computer science who know nothing in finance might fit well on quant developer even if the requirements says CFA preferred.\n",
    "    Be very tolerative on other fields even if he/she lacks of some skills on resume.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            # Create the messages for the conversation with the model\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"Here is the job description:\\n\\n{job_description}\\n\\nAnd here is the resume:\\n\\n{resume_text}\"} \n",
    "            ]\n",
    "            \n",
    "            if strict_requirements is not None and strict_requirements != \"\":\n",
    "                messages.append({\"role\": \"user\", \"content\": f\"And here are the strict requirements you need to check:\\n\\n{strict_requirements}\"})\n",
    "\n",
    "            # Request a completion from the OpenAI API\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo-16k\",\n",
    "                messages=messages,\n",
    "            )\n",
    "\n",
    "            # Extract the model's response\n",
    "            model_response = response['choices'][0]['message']['content']\n",
    "\n",
    "            # Strictly match the response to 'Yes' or 'No'\n",
    "            if \"yes\" in model_response.strip().lower():\n",
    "                print(model_response)\n",
    "                return True\n",
    "            elif \"no\" in model_response.strip().lower():\n",
    "                print(model_response)\n",
    "                return False\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected response from AI: {model_response}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            print(\"Retrying in 5 seconds...\")\n",
    "            time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005af890",
   "metadata": {},
   "source": [
    "## Search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c549dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_resume(text):\n",
    "    # OpenAI key\n",
    "    prompt = \"\"\"Strictly Structure the candidate's raw resumes in the following format using both resume content and your knowledge externally in human readable way.\n",
    "     \"Contact information\": {\n",
    "        \"Name\": \"<their name>\",\n",
    "        \"Email\": \"<their email>\",\n",
    "        \"Phone\": \"<their phone>\"\n",
    "        },\n",
    "    \"Summary\": In no more than 10 sentences, summary of candidate's current role, what's his/her specializations.\n",
    "    \"Level\": \"<approximate how many years of working experience does the candidate have, if not easy to calculate, just classify into new graduate, entry level, mid level, and senior level along with your approximation of years\"\n",
    "    \"Skills\": \"<List of their techinical skills, separate by comma>\",\n",
    "    \"Educations\": \"<Summary of candidate's education experience, like schools, degrees, and majors>\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the series of messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": text}\n",
    "    ]\n",
    "\n",
    "    # Request a completion\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-16k\",\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "    # Return the model's message from the response\n",
    "    return response['choices'][0]['message']['content']\n",
    "\n",
    "def on_result_select(event):\n",
    "    try:\n",
    "        # Get selected line index\n",
    "        selected_index = result_listbox.curselection()[0]\n",
    "        selected_text = result_listbox.get(selected_index)\n",
    "\n",
    "        # Retrieve the full resume using the ID from selected_text, and generate a summary\n",
    "        try:\n",
    "            resume_text = fetch_resume_by_id(selected_text)  # Use the function you already have to get resume text by id\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching resume with id {selected_text}: {str(e)}\")\n",
    "            tk.messagebox.showerror(\"Error\", f\"Error fetching resume with id {selected_text}: {str(e)}\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            resume_summary = process_resume(resume_text)\n",
    "        except Exception as e:\n",
    "            print(f\"API overload while processing resume with id {selected_text}: {str(e)}\")\n",
    "            time.sleep(5)  # Retry after 5 seconds\n",
    "            try:\n",
    "                resume_summary = process_resume(resume_text)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process resume with id {selected_text} after retrying: {str(e)}\")\n",
    "                tk.messagebox.showerror(\"Error\", f\"Failed to process resume with id {selected_text} after retrying: {str(e)}\")\n",
    "                return\n",
    "\n",
    "        # Display the summary\n",
    "        tk.messagebox.showinfo(\"Resume Summary\", resume_summary)\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error in on_result_select: {str(e)}\")\n",
    "        tk.messagebox.showerror(\"Error\", f\"Unexpected error: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f06733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a revised version of your `search_resumes` function.\n",
    "# I've assumed that the 'id' field in the match object is the resume id.\n",
    "\n",
    "def search_resumes(top_k):\n",
    "    global result_listbox  # Declare result_listbox as global\n",
    "    if result_listbox is None:\n",
    "        result_listbox = tk.Listbox(root)\n",
    "        result_listbox.grid(row=10, column=0, padx=10, pady=10, sticky=\"ew\")\n",
    "    else:\n",
    "        result_listbox.delete(0, \"end\")\n",
    "\n",
    "    # Fetch all resumes from MongoDB instead of the local JSON file\n",
    "    json_resumes = fetch_all_resumes_from_db()\n",
    "    print(\"loaded json resumes\")\n",
    "    \n",
    "    job_description = job_description_entry.get(\"1.0\", \"end-1c\")  \n",
    "    keyword = keyword_entry.get(\"1.0\", \"end-1c\")\n",
    "\n",
    "    print(f\"Job Description: {job_description}\")  \n",
    "    print(f\"Keyword: {keyword}\")  \n",
    "\n",
    "    try:\n",
    "        top_matches = get_top_matches(index, embed, job_description, top_k=top_k)\n",
    "        print(f\"Top Matches: {top_matches}\")  \n",
    "\n",
    "        matches = top_matches['results'][0]['matches']\n",
    "        filtered_matches = []\n",
    "\n",
    "        for match in matches:\n",
    "            resume_id = match['id']\n",
    "\n",
    "            # Fetch the resume text from MongoDB using the ID\n",
    "            resume_text = fetch_resume_by_id(resume_id)\n",
    "\n",
    "            if keyword and not boolean_search(resume_text, keyword):\n",
    "                continue  # Skip this match if it doesn't pass the boolean search\n",
    "\n",
    "            filtered_matches.append(resume_id)\n",
    "        \n",
    "        if AI_checking_checkbox.get():\n",
    "            strict_requirements = strict_requirements_entry.get(\"1.0\", \"end-1c\")\n",
    "            for match in filtered_matches:\n",
    "                resume_text = fetch_resume_by_id(match)\n",
    "                print(f\"AI checking for {match}\")\n",
    "                if AI_check(resume_text, job_description, strict_requirements):\n",
    "                    result_listbox.insert(\"end\", match)\n",
    "        else:\n",
    "            for match in filtered_matches:\n",
    "                result_listbox.insert(\"end\", match)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")  \n",
    "        messagebox.showerror(\"Error\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0174cab9",
   "metadata": {},
   "source": [
    "## Delete function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc530059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete entry in Pinecone\n",
    "def pinecone_delete(id_to_delete):\n",
    "    \"\"\"\n",
    "    Delete entries from a Pinecone index.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Delete the entries\n",
    "    delete_op = index.delete(id_to_delete, namespace=index_name)\n",
    "    print(delete_op)\n",
    "    # Make sure the operation completes before continuing\n",
    "    #delete_op.result()\n",
    "    \n",
    "    print(id_to_delete, \"deleted from Pinecone\")\n",
    "\n",
    "    \n",
    "# Delete entry in MongoDB\n",
    "def mongo_delete(id_to_delete):\n",
    "    \"\"\"\n",
    "    Delete specific document from a MongoDB collection.\n",
    "    \"\"\"\n",
    "    \n",
    "    collection.delete_one({ \"id\": str(id_to_delete) })\n",
    "    \n",
    "    print(id_to_delete, \"deleted from MongoDB\")\n",
    "    \n",
    "def delete_doc():\n",
    "    id_to_delete = delete_entry.get(\"1.0\", \"end-1c\")\n",
    "    print(id_to_delete)\n",
    "    \n",
    "    if id_to_delete == \"\":\n",
    "        return\n",
    "    \n",
    "    # Ask for user's confirmation to prevent accidental delete\n",
    "    confirm = tk.messagebox.askquestion (\"Confirmation\", f\"Are you sure you want to delete ID: {id_to_delete}?\" ,icon = 'warning')\n",
    "    if confirm == \"yes\":    \n",
    "        print(f\"Deleting ID: {id_to_delete}\")\n",
    "        pinecone_delete(id_to_delete)\n",
    "        mongo_delete(id_to_delete)\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ae1254",
   "metadata": {},
   "source": [
    "## GUI implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "604b0df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 18:40:47.313 python[40629:74362601] TSM AdjustCapsLockLEDForKeyTransitionHandling - _ISSetPhysicalKeyboardCapsLockLED Inhibit\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    class CreateToolTip:\n",
    "        def __init__(self, widget, text='widget info'):\n",
    "            self.widget = widget\n",
    "            self.text = text\n",
    "            self.widget.bind(\"<Enter>\", self.enter)\n",
    "            self.widget.bind(\"<Leave>\", self.close)\n",
    "\n",
    "        def enter(self, event=None):\n",
    "            x, y, _, _ = self.widget.bbox(\"insert\")\n",
    "            x += self.widget.winfo_rootx() + 25\n",
    "            y += self.widget.winfo_rooty() + 20\n",
    "            self.tw = tk.Toplevel(self.widget)\n",
    "            self.tw.wm_overrideredirect(True)\n",
    "            self.tw.wm_geometry(f\"+{x}+{y}\")\n",
    "            label = tk.Label(self.tw, text=self.text, background=\"#ffffff\", relief='solid', borderwidth=1,\n",
    "                             wraplength=180)\n",
    "            label.pack(ipadx=1)\n",
    "\n",
    "        def close(self, event=None):\n",
    "            if self.tw:\n",
    "                self.tw.destroy()\n",
    "\n",
    "    class PrintLogger:  # create file like object\n",
    "        def __init__(self, textbox):  # pass reference to text widget\n",
    "            self.textbox = textbox  # keep ref\n",
    "\n",
    "        def write(self, text):\n",
    "            self.textbox.insert(tk.END, text)  # write text to textbox\n",
    "            self.textbox.see(tk.END)\n",
    "            self.textbox.update_idletasks()  # update GUI\n",
    "\n",
    "            \n",
    "    def flush_databases_with_confirmation():\n",
    "        MsgBox = tk.messagebox.askquestion ('Flush Database','Are you sure you want to flush the database?',icon = 'warning')\n",
    "        if MsgBox == 'yes':\n",
    "            flush_databases()\n",
    "\n",
    "    def on_closing():\n",
    "        # Reset standard output to default\n",
    "        sys.stdout = sys.__stdout__\n",
    "\n",
    "        # Any necessary cleanup here\n",
    "        # Then destroy window\n",
    "        root.destroy()\n",
    "        # And finish the event loop\n",
    "        root.quit()\n",
    "        \n",
    "        \n",
    "    root = ThemedTk(theme=\"plastik\")\n",
    "    root.title(\"Resume Search Engine\")\n",
    "    \n",
    "    job_description_label = tk.Label(root, text=\"Job Description:\")\n",
    "    job_description_entry = scrolledtext.ScrolledText(root, width=80, height=10)\n",
    "    CreateToolTip(job_description_entry, \"(Optional) Describe ideal candidates or paste job descriptions in natural English or paste Job description here.\")\n",
    "    \n",
    "    keyword_label = tk.Label(root, text=\"Keyword:\")\n",
    "    keyword_entry = scrolledtext.ScrolledText(root, width=100, height=2) \n",
    "    CreateToolTip(keyword_entry, \"(Optional) Boolean Search, for example: (Python and C++ or quant*). please check documentations on how to use boolean search \")\n",
    "    \n",
    "    top_k_label = tk.Label(root, text=\"Searching Scope:\")\n",
    "    CreateToolTip(top_k_label, \"The amount of resumes in the Database used for searching, Larger Scope -> preciese but slow\")\n",
    "    top_k_entry = tk.Entry(root)\n",
    "    top_k_entry.insert(0, \"100\")  # Setting default value as 200\n",
    "    CreateToolTip(top_k_entry, \"Larger the scope -> the better the reuslts but will be SLOW! Recommand not exceed 500\")\n",
    "    \n",
    "    strict_requirements_label = tk.Label(root, text=\"Strict Requirements:\")\n",
    "    CreateToolTip(strict_requirements_label, \"Enable AI checking to use, AI will check the requirements strictly\")\n",
    "    strict_requirements_entry = scrolledtext.ScrolledText(root, width=100, height=2)\n",
    "    CreateToolTip(strict_requirements_entry, \"(Optional, select enable AI checking box to use) Specify any strict requirements for the job. AI will strictly look at those requirements. e.g. This person must have a phd in Computer Science and know ETL, AWS, and SQL.\")\n",
    "    \n",
    "    # Delete label\n",
    "    delete_label = tk.Label(root, text=\"Delete resumes: \")\n",
    "    # Delete entry\n",
    "    delete_entry = scrolledtext.ScrolledText(root, width=30, height=2)\n",
    "    CreateToolTip(delete_label, \"Please use this function carefully\")\n",
    "    \n",
    "    AI_checking_checkbox = BooleanVar()\n",
    "    AI_checking_checkbox.set(False)  # Unchecked by default\n",
    "    AI_checking_checkbutton = tk.Checkbutton(root, text=\"Enable AI checking\", variable=AI_checking_checkbox)\n",
    "    CreateToolTip(AI_checking_checkbutton, \"(Optional) Check this box to enable AI checking of resumes. AI will check resumes one by one accoridng to JD. Precise but Slow!\")\n",
    "    \n",
    "    search_button = tk.Button(root, text=\"Search\", command=lambda: search_resumes(int(top_k_entry.get())), font=Font(size=20))\n",
    "    CreateToolTip(search_button, \"click here to search resumes\")\n",
    "    \n",
    "    upload_button = tk.Button(root, text=\"Upload Resumes\", command=upload_resumes)\n",
    "    CreateToolTip(upload_button, \"Select a folder, will automatically upload all resumes in the folder and its subdirectories\")\n",
    "    \n",
    "    flush_button = tk.Button(root, text=\"Flush Database\", command=flush_databases_with_confirmation)\n",
    "    CreateToolTip(flush_button, \"Warning! This button will Permanently delete all data from the database.\")\n",
    "    \n",
    "    # Delete button\n",
    "    delete_button = tk.Button(root, text=\"Delete\", command=delete_doc, cursor=\"hand2\")\n",
    "    CreateToolTip(delete_button, \"Warning! This button will cause permanent loss of information.\")\n",
    "    \n",
    "    result_label = tk.Label(root, text=\"Results:\")\n",
    "    \n",
    "    logger_box = scrolledtext.ScrolledText(root, width=80, height=10)\n",
    "    CreateToolTip(logger_box, \"Console messages here, You will be able to see the reasoning given by AI\")\n",
    "    pl = PrintLogger(logger_box)\n",
    "    sys.stdout = pl\n",
    "\n",
    "    job_description_label.grid(row=0, column=0, sticky=\"w\")\n",
    "    job_description_entry.grid(row=1, column=0, padx=10, pady=10, sticky=\"ew\")\n",
    "\n",
    "    keyword_label.grid(row=2, column=0, sticky=\"w\")\n",
    "    keyword_entry.grid(row=3, column=0, padx=10, pady=10, sticky=\"ew\")\n",
    "\n",
    "    top_k_label.grid(row=4, column=0, sticky=\"w\")\n",
    "    top_k_entry.grid(row=4, column=1, sticky=\"ew\")\n",
    "\n",
    "    strict_requirements_label.grid(row=5, column=0, sticky=\"w\")\n",
    "    strict_requirements_entry.grid(row=5, column=1, sticky=\"ew\")\n",
    "    \n",
    "    # Delete label entry grid\n",
    "    delete_label.grid(row=0, column=1, sticky=\"w\")\n",
    "    delete_entry.grid(row=1, column=1, padx=0, pady=0, sticky=\"nw\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    AI_checking_checkbutton.grid(row=6, column=0, sticky=\"w\")\n",
    "\n",
    "    search_button.grid(row=7, column=0, padx=10, pady=10, sticky=\"ew\")\n",
    "    upload_button.grid(row=8, column=0, padx=10, pady=10, sticky=\"ew\")\n",
    "    # resize delete button\n",
    "    delete_button.grid(row=1, column=1, padx=200, pady=0, sticky=\"ne\")\n",
    "\n",
    "    result_label.grid(row=9, column=0, padx=10, pady=10, sticky=\"w\")\n",
    "    \n",
    "    result_listbox = tk.Listbox(root)\n",
    "    result_listbox.grid(row=10, column=0, padx=10, pady=10, sticky=\"ew\")\n",
    "    result_listbox.bind('<Double-1>', on_result_select)\n",
    "\n",
    "    logger_box.grid(row=11, column=0, padx=10, pady=10, sticky=\"ew\")\n",
    "    flush_button.grid(row=12, column=0, padx=10, pady=10, sticky=\"e\")\n",
    "    \n",
    "    root.grid_columnconfigure(0, weight=1)\n",
    "    root.grid_rowconfigure((1, 3, 10, 11), weight=1)\n",
    "\n",
    "    root.protocol(\"WM_DELETE_WINDOW\", on_closing)\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b240b4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aca64b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
